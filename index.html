<!DOCTYPE html>
<html>
<head>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script>
        let session;

        async function loadModel() {
            try {
                console.log("Loading ONNX model...");
                session = await ort.InferenceSession.create("https://pub-844b45300a5f448d89068bb547a4a216.r2.dev/model_q4.onnx");
                console.log("ONNX model loaded!");
                window.ReactNativeWebView.postMessage("MODEL_LOADED");
            } catch (error) {
                console.error("Error loading ONNX model:", error);
                window.ReactNativeWebView.postMessage("MODEL_ERROR");
            }
        }

        async function classifyImage(base64Image) {
            try {
                const inputTensor = new ort.Tensor("float32", new Float32Array(base64Image), [1, 3, 224, 224]);
                const results = await session.run({ input: inputTensor });
                window.ReactNativeWebView.postMessage(JSON.stringify(results));
            } catch (error) {
                console.error("Error processing image:", error);
                window.ReactNativeWebView.postMessage("ERROR_PROCESSING_IMAGE");
            }
        }

        window.onload = loadModel;
    </script>
</head>
<body>
    <h3>ONNX Model Running in WebView</h3>
</body>
</html>
